.output chapter6.wd
.bookmark the-community
+ 0MQ社区

有人问我0MQ为什么这么特别。我的标准答案是：毫无疑问，0MQ是“怎么写出满足21世纪需求的分布式软件”这种问题的最佳答案。但除此之外，0MQ更因为其社区而与众不同。这才是狼与羊的最大区别。

主要有三种开源模式。一种是大公司狂写代码抢占市场，这是Apache基金会采取的模式。第二种是小的团队或公司为实现梦想而奋斗，这是最常见的开源模式，同样也可以在商业上获取成功。最后是一群积极进取而又彼此不同的人，在一系列问题上各展神通，这是Linux模式，也是我们渴望0MQ成为的模式。

再怎么强调开源社区的能量和持久性也不为过，而且貌似也没有什么比其创造的软件更久远。这是因为社区选了最棒的问题、一步步仔细的解决它、年复一年细心的照顾它、直到不再有用才悄无声息的扔掉它。

想真正从0MQ受益，你得明白它的社区。这条路的某个路口，你可能会想提交补丁、提意见或插件。你也可能会寻求帮助。你还可能孤注一掷将0MQ用在你的事业之中，那即便我是0MQ背后公司的CEO，还是得坦诚告诉你，社区远远比我们公司更为重要、也更有意义。

这一章节，我将从多角度来观察并总结0MQ社区协同工作的合约，我们称之为[http://rfc.zeromq.org/spec:22 C4]。你会发现这些讨论对你的工作大有裨益。我们也为一些成功的闭源项目修改了C4。

我们会提到：

* 0MQ系列项目的大概结构
* 什么是“软件架构”
* 为什么我们用LGPL而非BSD许可
* 我们是怎么设计并培养0MQ社区的
* 0MQ背后的商业
* 谁拥有0MQ的源代码
* 怎么制作补丁并提交给0MQ
* 谁决定了补丁最终合入0MQ代码
* 我们如何保证已有代码的兼容性
* 我们为什么不用公开的git分支
* 谁决定了0MQ的路线图
* 一个修改{{libzmq}}的实例

++ 0MQ社区结构

你可能知道0MQ是LGPL许可的项目。事实上，它是围绕{{libzmq}}核心库的一系列项目的集合。我用一个扩展星系来描述它：

* {{libzmq}}是0MQ最最核心的库。它带有底层C的API，用C++完成的。这部分代码很乱，主要是因为用C++高度优化过，而C++本身太难驾驭。Martin Sustrik完成其中大部分代码，如今，已经有好几十号人维护着代码的不同部分。

* 围绕{{libzmq}}，大概有50种语言的//绑定//。这些独立项目是给0MQ提高了一些高层API，或者至少把底层API映射到其他语言。它们的质量参差不齐，从一些试验到棒至不可思议的项目都有。可能最让人吃惊的就是[https://github.com/zeromq/pyzmq PyZMQ]，它是社区最棒的项目之一。如果你是某种语言绑定的作者，你真的应该研究一下PyZMQ是怎么写好代码并维护好社区的。

* 很多语言有多个版本的绑定（Erlang, Ruby, C#等），它们由不同人或用不同方法实现的。但是我们并不约束它们，因为它们并非“官方”绑定。使用、贡献或者无视它们都是你的自由。

* 还有一系列用其他语言实现的{{libzmq}}，最早是JeroMQ，一种Java的翻译，如今用在NetMQ（一个C#栈）中。这些原生的库都提供了相同或相似的API，和{{libzmq}}一样使用相同的协议（ZMTP）。

* 在这些绑定之上，还有很多用0MQ做出来的项目。你可以在wiki中的“Labs”页看到一长串项目，他们多多少少都用到了0MQ。其中包括一些框架、web服务（Mongrel2）、中间件（Majordomo）以及公司的开源工具（Strom）。

{{Libzmq}}、大部分绑定及其他外围项目都在Github上的[https://github.com/organizations/zeromq 0MQ组织]中。这个组织是由一群资深的绑定作者“管理”的。其实也没什么好管理的，因为基本上都是自己管自己的项目，也没有什么纷争。

iMatix，我的公司，在这个社区中有着特殊的角色。我们拥有商标，强制它们彼此分离，以此来保证你下的每个叫“ZeroMQ”的包都是你真正想要的。有些人也尝试过劫持这个名字，或许是觉得“自由软件”就意味着它不属于任何人，没人会站出来保护它。这一章里，你就会懂得我们（我是指社区而非公司）有多重视软件背后的流程。iMatix公司支撑着整个社区，就是靠强制每个称自己为“ZeroMQ”或“0MQ”的东西都要走这个流程。我们为软件和打包投入了金钱和时间，具体原因我稍后会解释。

这可不是个慈善练习。0MQ是一个利益驱动的项目，事实上，是个非常赚钱的项目。利润也都分给了那些投资给它的人们。很简单：花时间在0MQ上成为专家，或者用0MQ作出什么有用的东西，你会发现无论是个人、团队、还是公司的价值都会有提升。iMatix和社区中的每个人一样，享受这些好处。这对每个人来说都是双赢的。当然不包括那些为此感到恐惧却又无法摆脱的竞争对手。0MQ主宰了大规模分布式软件的未来。

我的公司不仅是社区的依靠，其实我们建立了整个社区。这是我们有意为之，从2007年0MQ的最初设想，实际上有两个项目。一个是技术上，怎么建造一个更好的消息系统。另一个就是怎么创造一个社区，引领软件走向成功。结果是软件挂掉了，社区却成功活下来了。

+++ 怎么建造相当大规模的架构

据说（至少人们读到过），建造相当大规模的软件有两种办法。其一是花大量的钱把问题扔个最聪明的人，并祈祷结果别是把人都逼走了。如果你有足够经验，能把人团结起来，还能瞄准目标，甚至足够幸运，还是能做到的。

但是不是每个人都能获得百万投资。剩下的人如果想建造大规模软件，只有第二种选择，那就是开源，更具体的说是//自由软件//。如果你想问怎么为你造的软件选一个许可，你问对问题了。

聪明睿智的Eben Moglen曾经说过，软件许可是一个社区建立的缔约。我大概在10年前听到这个说法，而想法随之而来——//我们能否依此建立自由软件社区呢？//

十年后，答案是“yes”，而且这似乎是有科学道理的。我说“似乎”是因为我们还没有足够的证据，因为没有其他人用文档记录下同样的过程。这也是为什么我写了[http://softwareandsilicon.com/chapter:2#toc5 社区架构]。0MQ出现在Wikidot，遵循[http://www.digistan.org 数字标准组织](Digistan)以及[http://www.ffii.org 自由信息平台组织]（又名FFII，一个为软件专利而作斗争的无政府组织）之后。这些都是在一些不怎么成功的项目（如Xitami和Libero）之后出现的。从这些项目的漫长历史中我收获到的启示是：如果你想建造一个真正大规模、长时间的软件，那就建造一个自由软件社区。

+++ 软件架构心理学

Dirkjan Ochtman向我指出[http://en.wikipedia.org/wiki/Software_architecture 软件架构]是“关于系统如何被合理的组织，包括软件的组件、之间的关系以及二者的属性”。对我来说，这个饶舌而无趣的术语就是为何我们悲催的不明白如何建造一个成功的大规模软件架构的原因之一。

架构是一门艺术，也是一门科学，是建造给人用的人工结构。如果说我在过去30年在建造越来越大的软件系统中学到了什么，那就是：//软件是关于人的事//。大的结构本身是没有什么意义的，他们被//人//用成什么样才最重要。而在软件中，人的使用从那些建造这些软件的程序员开始。

软件架构中最核心的问题是由人的心理驱动而非技术驱动。心理从各方面影响我们的工作。我能指出一些团队看起来变呆了的原因，比如他们扩建团队了，或者他们远距离分散工作。但这是不是意味着团队越小，效率越高呢？那像0MQ这样一个大的全球性社区又是如何成功的呢？

0MQ的成功并非偶然。它是经过有意的设计，是我在最早代码出现在Bratislava的地下室里时的贡献。这个设计是基于我的“社会架构”，也就是[http://en.wikipedia.org/wiki/Social_architecture 维基百科]定义的“设计一个鼓励社会个体追求一些或一系列目标的环境”。我把把更具体的定义为“过程、产品、经过计划、设计并最终成长为在线社区”。

社会架构的信条之一就是//我们怎么组织//比//我们是谁//更重要。同样的团体，组织不同，可能就会导致完全不同的结果。普通人经过很好的组织也可以完成专家级别的工作。如果你是一个大型0MQ应用的架构师，你就要找到了正确模式来帮助别人更好的工作。干对了，你的项目就能成功。干错了，你的项目也就失败了。

心理要素的最重要的两点是：我们并不善于理解复杂的东西，但我们善于协作将大的问题分而治之。我们是高度社会化的动物，在正确的人群中也拥有一定程度的智能。

那么下面就是一份软件架构的心理学要素简要清单：

* **笨**：我们的精神带宽是有限的，因此到了某种程度我们就都笨了。因此架构需要简单并容易理解。第一条：任何时候，简单胜过
功能性。如果你都不能在阴暗寒冷的周一早咖啡前明白的架构，那就太复杂了。

* **自私**：我们都喜欢按自己的兴趣来，那么架构必须留足空间和可能，能让全部人都能受益。自私并不总是那么直接，比如说，我花了数小时帮别人理解某事，而这对我来说节省了之后好几天的时间。

* **懒惰**：我们做了很多的假设，其中大部分是错误的。我们都很乐于轻松的测试来获得假设的结果，因此架构也要让这成为可能。具体的来说，这也是要求简单。

* **嫉妒**：我们都嫉妒别人，因此我们会战胜愚蠢和懒惰来证明别人是错的。因此架构需要创造一点公开公平竞争的空间。

* **害怕**：我们都不愿意冒险，尤其当这会让我们觉得自己很笨的时候。害怕失败经常会成为人们的借口，甚至不惜与笨人为伍。因此架构也要让试验的代价变小，让人有机会冒着很小的风险追求成功。

* **互利互惠**：我们在禁止抄袭和维持公正上会付出额外的代价。因此架构要有强力的规则，告诉人们可以合作，但是有些事不能做。

* **约定俗成**：除了害怕和懒惰，其实我们还是乐于遵守规定的。也就是说，如果模式是正确、清楚、成文并强制执行的，我们自然而然会选择正确的道路。

* **骄傲**：我们还是很看中自己的社会地位的，而且我们为了避免被看作愚蠢无能，会非常努力。架构要确保每个人的功劳都被记住，为了别人对自己工作的评价，我们甚至会不眠不休。

* **贪婪**：我们最终还是利益化的动物（见自私），因此架构还是要给一些利益上的刺激。可以是被称赞为专家，也可以是从中获取金钱。无论如何，多少还是要有一些利益的刺激。把架构当作一个巨大的市场，而不是一个工程上的设计。

这些策略在大小规模的组织和团队里都很有用。

+++ 契约的重要性

我们来谈谈一点争议不断但是非常重要的事，那就是选一个什么样的许可。我将用“BSD”代指MIT，X11，BSD，Apache等许可，用“GPL”代指GPLv3，LGPLv3以及AGPLv3。最显著的差距是需不需要把分出去的版本分享回原版本，这样可以阻止别人占有该软件，这样就可以保证“自由”。

软件许可并不是技术上的契约，因为你都不需要签字。但是总的来说，叫他契约还是很有用的，因为它规定了各方的责任，并且在法院里也是有法律保证的（版权法）。

你可能会问，开源为什么还需要契约？确实，人们行为正派、意愿高尚，通过无私的合作贡献给开源世界。但是，“少即是多”在任何地方都能有效么？规则越多就意味着自由越少？我们真的需要律师告诉我们怎么协同工作？看起来，给亲密无间的自由开源软件加上这么多限制条件，显得有些愤青而斤斤计较。

但是事实是人类社会没有那么完美，我们不是天使也不是恶魔，而是万年不变、自私的利己主义者。无论事业、婚姻、集体活动，我们早晚会互不关心，甚至争斗。

换句话说：集体活动会有两种极端的结果。要么就是失败、冷漠、意义全无，最后人走茶凉，甚至还会引发斗争。要么就是成功、紧密团结、荣誉，人们获得能力、掌控，而且还经常伴随着金钱。

而良好的契约，其实是保护那些有价值的关系，让其远离纷争。在婚前就清楚明晰达成关于离婚事宜的夫妇最后反而不会离婚。而一开始就规定好怎么解决双方纷争（比如一方偷走另一方的客户或雇员）的生意最后都不怎么会黄。

类似的，一个软件项目，如果一开始就把合作破裂的契约写清楚了，最后反而不容易破裂。另一种办法是把项目变成一个大的组织，这样就可以增强团队合作的能力（也可能导致失去组织的支持以及名号）。这就是Apache基金会的工作模式。依我的经验来看，建设这样团队也有其代价，比如会迎合那些有钱的参与者（那些能支撑的起巨额花费的参与者）。

在开源或自由社区项目里，合作破裂经常是因为开了另外一个分支，那么社区就会分裂成两拨或更多，其后就出现了不同的版本。在项目的蜜月期，自然没有这样的问题。而当项目变得值钱了，或者主要作者开始缺钱了，那么好的意愿、慷慨大方也就不见了。

因此我们在谈论你写的代码或你用的代码的时候，愤青似的谈一谈许可还是有用的。扪心自问，别问什么“哪种许可能吸引更多的贡献者”，那取决于目标陈述和贡献过程。要问自己“如果项目内斗并分裂成了三拨人，哪种许可能拯救我们？”，或问“如果整个团队都被一个邪恶的大公司收买了，而公司想把代码变成私有产品，哪种许可能拯救我们？”。

长期的项目，除了能享受愉快的岁月，还得忍受难熬的时光。

如果BSD项目分离出去了，想合回去就不太容易了。实际上，BSD项目被分离出去都是有预谋的，每次BSD代码都被用成了商业项目，这已经发生过很多次了。但是，当GPL项目分离出去，合回来还是很容易的。

这里讲一讲GPL的故事。20世纪80年代，尽管社区的程序员已经很习惯于开放分享彼此的代码了，但是他们还是尽可能少的使用许可，因为也没有涉及到金钱。那时，出现了一种很重要的语言栈，叫Emacs，最开始是Richard Stallman用Lisp完成的。另一个程序员James Gosling（他之后给我们带来了Java）在其他贡献者的帮助下，用C重写了Emacs。大家都以为这是自由的，因此Stallman得到了这份代码并用它当作自己C版本的基础。之后Gosling把这份代码卖给了一个大公司，公司反过头来禁止大家分发这份代码。Stallman发现这种贩卖集体智慧的行为根本没有原则可言，因此开始制作一种可复用的许可，防止社区重蹈覆辙。

最后的成果就是GNU通用许可，它用传统的版权来强制保证可再混合。这份许可很快传播到其他领域，比如摄影、音乐领域的创意共享许可。在2007年，第三版姗姗来迟，是对微软和其他大公司的反击。这已经是一份又长又复杂的文档，但是版权律师们对此已经很熟悉了，而且据我所知，公司都不介意使用GPL许可的软件、库，因为界限已经划分的很清楚了。

也就是说，一份好的契约（我认为现代GPL已经是对软件最好的许可）对于没有预先协议、没有组织、仅仅因为意愿而聚集在一起工作的程序员来说是很有好处的。这让协同工作代价更小，让斗争变成健康的竞争。GPL不仅仅定义了分支要怎么做，实际上它很鼓励分支，把分支当作一种试验和学习的工具。在一份更自由的许可保证下的项目，可能会被一份分支干掉了，而GPL的项目却因为分支而变得更有活力，因为在许可的保证下，成功的试验可以被合回主分支。

是的，也有很多很火的BSD项目，也有很多挂掉的GPL项目。归纳都是不精确的。一个项目成功与否取决于很多因素。但是，正如竞技项目中，运动员要把握住每一个优势。

另外一个重要的BSD与GPL对比，我称之为“漏斗”，就像往盆里倒水，而底部却有那么一个小小的洞。


+++ 快来吃我

故事是这样的。这是我的一位同事的朋友的表亲的姐夫。他的名字一直没变，叫Patrick。

Patrick是一位精通高级网络拓扑的计算机博士。他在花了两年和积蓄创建了一个新的产品，选择了BSD许可，因为他相信这样可以有更多的人用。他在自己的阁楼上，用自己的钱，非常自豪的公开了自己的工作成果。人们惊叹于这是多么棒的一份成果，很快，他的邮件列表就被活动、补丁还有欢快的聊天挤爆了。很多公司告诉他，他的成功给他们节约了数以百万的金钱。甚至有公司愿意花钱邀请他做顾问或做培训。他被会议邀请去做演讲，开始收集那些刻有他名字的徽章。他开始做生意，还雇了一位朋友，并梦想着把生意做大。

然后有一天，有人告诉他有一个GPL许可的项目从他的工作中分离出去了。他被惹怒了，质问那些开源社区的人怎么能不知羞耻的盗窃他的成果。邮件列表里甚至为了BSD项目更换许可为GPL项目是否合法而争论不休。结论是，可以。他决定无视新项目，但是很快却发现从那个项目里产生的新补丁//根本不能合回//他自己的项目。

更糟糕的是，GPL项目变得更活跃，他的代码贡献者开始慢慢转向那个项目提交补丁。再一次，他没法用那些补丁，他觉得自己被背叛了。Patrick陷入了沮丧，他的女朋友跟了另一个叫Patrice的国际金融交易员，他也停止了继续自己的工作。他觉得遭到背叛，陷入了悲伤。他炒掉了朋友，朋友也背地里说他的坏话。最终，Patrick在一个云公司得到了一份软件主管的工作，在他40岁的时候就不再碰程序了。

可怜的Patrick，我真为他感到遗憾。我问他“你为什么不用GPL呢？”“因为它是一份严格的病毒许可”他回答到。我告诉他“你可能是一个博士，你也是我的同事的朋友的表亲的姐夫，但是你其实是个不折不扣的傻瓜，难怪Monique会离开你。你公开了你的工作，邀请别人来偷你的代码，却只要求别人把‘请来偷代码’的声明写进成果，而别人真的这么干了，你却沮丧至极。你还是个伪君子，别人偷偷的干你反而不觉得，别人公开的这么做，你还觉得遭到背叛。”

看到自己的辛苦工作最后却被一帮更聪明的人用来和你作对，这确实是很痛苦的，那么到底是怎么造成的呢？每个用到了BSD代码的私有项目都注意到了这一点。一份公开的GPL分支或许并不太光彩，但是它足以自保。

BSD就像食物。它字里行间（我是指隐喻）悄悄的说“快来吃我”（原文：It literally (and I mean that metaphorically) whispers "eat me" in the little voice one imagines a cube of cheese might use when it's sitting next to an empty bottle of the best beer in the world, which is of course Orval, brewed by an ancient and almost extinct order of silent Belgian monks called //Les Gars Labas Qui Fabrique l'Orval//.）。BSD许可和它的近亲MIT/X11一样，最初是为伯克利大学用来公布工作成果而设计的。这是一种将受资助的技术以低价公开出去，想以价格优势拼得市场份额。BSD是一种//杰出//的策略工具，但是也只有那些大公司才能负担的起。Apache许可就是BSD的一种。

对像我们这样的小生意而言，我们的投资就像珍贵的子弹，泄漏工作成果是无法忍受的。能分得市场份额当然好，但是我们无法忍受养大了竞争对手。BSD网络技术栈已经在网上终结了Windwos的扩展，我们无法承受与本该是同盟的人做斗争，我们也无法承受一点事业上的错误，因为那样意味着我们得解雇人。

最后归结到经济行为和游戏理论。//我们选的许可改变了那些用我们的成果的人的地位。//在软件工业，有朋友、敌人和食物。BSD让大多数人视我们为食物。闭源让大多数人视我们为敌人（你//喜欢//为软件付钱么？）GPL让大多数人（除了像Patricks那样的人）成了我们的同盟。任何0MQ的分支都和0MQ保持许可兼容，这样我们就可以//鼓励//分支，把它当作有价值的试验。是阿，看别人尝试拿走我们的东西看起来有点奇怪，但是问题是，//任何时刻，只要我想，我都能拿回来//。

+++ 过程

如果到目前为止，你接受了我的理论，太棒了！现在，我将向你解释我们是怎么建立一个开源社区的。这就是关于我们怎么建立、培养、推动0MQ社区直至现在的。

作为社区的领袖，你的目标是推动人来到社区、探索社区；保证他们安全的探索，别干扰到别人；给那些有成功的发现的人以奖励；还要保证他们将知识分享给别人（不是我们请求他们，也不是他们慷慨大方，而是因为这就是铁律）。

这是一个迭代的过程。你创造一个小的产品，独自付出但却公之于众。然后你要围绕这个产品创造一个小的社区。如果你真的做到了，那么社区就会帮你设计并创造下一代产品。然后社区也可以发展向下一代。显然你还拥有部分社区，甚至是一个主要贡献者，但是你越想掌控，别人就越少参与进来。因此，在别人把你当作下一个麻烦之前，准备好自己的退休吧。

+++ 疯狂、美观、简洁

你需要一个足够简单、足够疯狂的目标，足以让人情愿从被窝里爬起来。你的社区需要吸引到最好最棒的一批人，因此目标要特别一点。对于0MQ，我们说我们要建立一个“史上最快的消息系统”，这可是一个很有分量的动机。如果我们说的是“一个聪明的传输层，能让你简单、容易的将公司里的移动部件连接起来”，我们估计已经失败了。

然后，你的工作必须美观、非常有用、非常有吸引力。你的贡献者其实都是你的用户，他们仅仅是想往下多深入一点。把工作做的简单、优雅而且干净。人们使用你的成果应该是一种享受。他们会//感觉//到，你真的把一个问题用他们没有想到的方式解决了，你就已经赢得了他们的心。

工作要很容易理解，很好用，然后也很好加入进来。很多项目都有进入的门槛：你得设身处地的想别人所想，要明白别人看你的网站的理由，“嗯～有点意思，但是……”然后他们就离开了。如果你想要别人留下来并试试看，哪怕只有一次。用Github，并把issue都留在那。

如果你做对了，你的社区就会更聪明，但是更重要的是，社区能够提供各种各样聪明的背景。这是很重要的。想法差不多的专家们是不能把一个问题的各个方面都研究透的，他们更可能犯错。多样性比受到的教育更重要。

+++ 与陌生人打交道

两个开始一起工作之前需要多少之前的准备？在大部分组织里，很多很多。但是你可以把开销降到接近为0，人们可以不需要见面、电话会议、开会或者出差，就能把角色和职责讨论清楚。

你需要有一些像我这样比较愤青的人，写清楚规则，这样就能让陌生人把精力花在合作而不是斗争上。GitHub和它的分支/合并策略是一个很好的示例。而你可能需要像我们的[http://rfc.zeromq.org/spec:22 C4规则书]这种东西来确保工作正常进行。

对于人们经常犯的错，C4（现在我用在每个新的开源项目里）里有详尽的、经过测试的答案，比如和别人窝在角落里离线工作，还声称“这样更快”。透明是获得信任的必要条件，也是扩展性的必要条件。强制每个改变都经过透明的过程，你就能得到可信的结果。

另一个开源软件开发者经常犯的错就是他们觉得高人一等。“我成立了这个项目，因此我觉得我的智力就比别人高”。这不仅仅是粗鲁的，而通常情况下根本就是错的，也是不公平的。规则也需要公平的对待每一个人，不能有歧视。你是社区的一部分，作为项目的成立者，你的工作不是把自己对产品的看法强加给别人，而是确保规则是好的、诚实的并且要//强制执行//。

+++ 无穷无尽的财产

One of the saddest myths of the knowledge business is that ideas are a sensible form of property. It's medieval nonsense that should have been junked along with slavery, but sadly it's still making too many powerful people too much money.

Ideas are cheap. What does work sensibly as property is the hard work we do in building a market. "You eat what you kill" is the right model for encouraging people to work hard. Whether it's moral authority over a project, money from consulting, or the sale of a trademark to some large, rich firm: if you make it, you own it. But what you really own is "footfall", participants in your project, which ultimately defines your power.

To do this requires infinite free space. Thankfully, GitHub solved this problem for us, for which I will die a grateful person (there are many reasons to be grateful in life, which I won't list here because we only have a hundred or so pages left, but this is one of them).

You cannot scale a single project with many owners like you can scale a collection of many small projects, each with fewer owners. When we embrace forks, a person can become an "owner" with a single click. Now they just have to convince others to join by demonstrating their unique value.

So in 0MQ, we aimed to make it easy to write bindings on top of the core library, and we stopped trying to make those bindings ourselves. This created space for others to make those, become their owners, and get that credit.

+++ Care and Feeding

I wish a community could be 100% self-steering, and perhaps one day this will work, but today it's not the case. We're very close with 0MQ, but from my experience a community needs four types of care and feeding:

* First, simply because most people are too nice, we need some kind of symbolic leadership or owners who provide ultimate authority in case of conflict. Usually it's the founders of the community. I've seen it work with self-elected groups of "elders", but old men like to talk a lot. I've seen communities split over the question "who is in charge?", and setting up legal entities with boards and such seems to make arguments over control worse, not better. Maybe because there seems to be more to fight over. One of the real benefits of free software is that it's always remixable, so instead of fighting over a pie, one simply forks the pie.

* Second, communities need living rules, and thus they need a lawyer able to formulate and write these down. Rules are critical; when done right, they remove friction. When done wrong, or neglected, we see real friction and argument that can drive away the nice majority, leaving the argumentative core in charge of the burning house. One thing I've tried to do with the 0MQ and previous communities is create reusable rules, which perhaps means we don't need lawyers as much.

* Thirdly, communities need some kind of financial backing. This is the jagged rock that breaks most ships. If you starve a community, it becomes more creative but the core contributors burn out. If you pour too much money into it, you attract the professionals, who never say "no", and the community loses its diversity and creativity. If you create a fund for people to share, they will fight (bitterly) over it. With 0MQ, we (iMatix) spend our time and money on marketing and packaging (like this book), and the basic care, like bug fixes, releases, and websites.

* Lastly, sales and commercial mediation are important. There is a natural market between expert contributors and customers, but both are somewhat incompetent at talking to each other. Customers assume that support is free or very cheap because the software is free. Contributors are shy at asking a fair rate for their work. It makes for a difficult market. A growing part of my work and my firm's profits is simply connecting 0MQ users who want help with experts from the community able to provide it, and ensuring both sides are happy with the results.

I've seen communities of brilliant people with noble goals dying because the founders got some or all of these four things wrong. The core problem is that you can't expect consistently great leadership from any one company, person, or group. What works today often won't work tomorrow, yet structures become more solid, not more flexible, over time.

The best answer I can find is a mix of two things. One, the GPL and its guarantee of remixability. No matter how bad the authority, no matter how much they try to privatize and capture the community's work, if it's GPL licensed, that work can walk away and find a better authority. Before you say, "all open source offers this," think it through. I can kill a BSD-licensed project by hiring the core contributors and not releasing any new patches. But even with a billion of dollars, I //cannot// kill a GPL-licensed project. Two, the philosophical anarchist model of authority, which is that we choose it, it does not own us.

++ The 0MQ Process: C4

When we say 0MQ we sometimes mean {{libzmq}}, the core library. In early 2012, we synthesized the {{libzmq}} process into a formal protocol for collaboration that we called the [http://rfc.zeromq.org/spec:22 Collective Code Construction Contract], or C4. You can see this as a layer above the GPL. In fact {{libzmq}} doesn't quite stick to C4 because for historic reasons we use Jira instead of the GitHub issue tracker. Apart from that, these are our rules, and I'll explain the reasoning behind each one.

C4 is an evolution of the GitHub [http://help.github.com/send-pull-requests/ Fork + Pull Model]. You may get the feeling I'm a fan of git and GitHub. This would be accurate: these two tools have made such a positive impact on our work over the last years, especially when it comes to building community.

+++ Language

> The key words "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT", "SHOULD", "SHOULD NOT", "RECOMMENDED",  "MAY", and "OPTIONAL" in this document are to be interpreted as described in RFC 2119.

By starting with the RFC 2119 language, the C4 text makes very clear its intention to act as a protocol rather than a randomly written set of recommendations. A protocol is a contract between parties that defines the rights and obligations of each party. These can be peers in a network or they can be strangers working in the same project.

I think C4 is the first time anyone has attempted to codify a community's rulebook as a formal and reusable protocol spec. Previously, our rules were spread out over several wiki pages, and were quite specific to {{libzmq}} in many ways. But experience teaches us that the more formal, accurate, and reusable the rules, the easier it is for strangers to collaborate up-front. And less friction means a more scalable community. At the time of C4, we also had some disagreement in the {{libzmq}} project over precisely what process we were using. Not everyone felt bound by the same rules. Let's just say some people felt they had a special status, which created friction with the rest of the community. So codification made things clear.

It's easy to use C4: just host your project on GitHub, get one other person to join, and open the floor to pull requests. In your README, put a link to C4 and that's it. We've done this in quite a few projects and it does seem to work. I've been pleasantly surprised a few times just applying these rules to my own work, like CZMQ. None of us are so amazing that we can work without others.

+++ Goals

> C4 is meant to provide a reusable optimal collaboration model for open source software projects.

The short term reason for writing C4 was to end arguments over the {{libzmq}} contribution process. The dissenters went off elsewhere. [https://github.com/zeromq/libzmq/graphs/contributors The 0MQ community blossomed] smoothly and easily, as I'd predicted. Most people were surprised, but gratified. There's been no real criticisms of C4 except its branching policy, which I'll come to later as it deserves its own discussion.

There's a reason I'm reviewing history here: as founder of a community, you are asking people to invest in your property, trademark, and branding. In return, and this is what we do with 0MQ, you can use that branding to set a bar for quality. When you download a product labeled "0MQ", you know that it's been produced to certain standards. It's a basic rule of quality: write down your process; otherwise you cannot improve it. Our processes aren't perfect, nor can they ever be. But any flaw in them can be fixed, and tested.

Making C4 reusable is therefore really important. To learn more about the best possible process, we need to get results from the widest range of projects.

> It has these specific goals:
> To maximize the scale of the community around a project, by reducing the friction for new Contributors and creating a scaled participation model with strong positive feedbacks;

The number one goal is size and health of the community--not technical quality, not profits, not performance, not market share. The goal is simply the number of people who contribute to the project. The science here is simple: the larger the community, the more accurate the results.

> To relieve dependencies on key individuals by separating different skill sets so that there is a larger pool of competence in any required domain;

Perhaps the worst problem we faced in {{libzmq}} was dependence on people who could understand the code, manage GitHub branches, and make clean releases--all at the same time. It's like looking for athletes who can run marathons and sprint, swim, and also lift weights. We humans are really good at specialization. Asking us to be really good at two contradictory things reduces the number of candidates sharply, which is a Bad Thing for any project. We had this problem severely in {{libzmq}} in 2009 or so, and fixed it by splitting the role of maintainer into two: one person makes patches and another makes releases.

> To allow the project to develop faster and more accurately, by increasing the diversity of the decision making process;

This is theory--not fully proven, but not falsified. The diversity of the community and the number of people who can weigh in on discussions, without fear of being criticized or dismissed, the faster and more accurately the software develops. Speed is quite subjective here. Going very fast in the wrong direction is not just useless, it's actively damaging (and we suffered a lot of that in {{libzmq}} before we switched to C4).

> To support the natural life cycle of project versions from experimental through to stable, by allowing safe experimentation, rapid failure, and isolation of stable code;

To be honest, this goal seems to be fading into irrelevance. It's quite an interesting effect of the process: //the git master is almost always perfectly stable//. This has to do with the size of changes and their //latency//, i.e., the time between someone writing the code and someone actually using it fully. However, people still expect "stable" releases, so we'll keep this goal there for a while.

> To reduce the internal complexity of project repositories, thus making it easier for Contributors to participate and reducing the scope for error;

Curious observation: people who thrive in complex situations like to create complexity because it keeps their value high. It's the Cobra Effect (Google it). Git made branches easy and left us with the all too common syndrome of "git is easy once you understand that a git branch is just a folded five-dimensional lepton space that has a detached history with no intervening cache". Developers should not be made to feel stupid by their tools. I've seen too many top-class developers confused by repository structures to accept conventional wisdom on git branches. We'll come back to dispose of git branches shortly, dear reader.

> To enforce collective ownership of the project, which increases economic incentive to Contributors and reduces the risk of hijack by hostile entities.

Ultimately, we're economic creatures, and the sense that "we own this, and our work can never be used against us" makes it much easier for people to invest in an open source project like 0MQ. And it can't be just a feeling, it has to be real. There are a number of aspects to making collective ownership work, we'll see these one-by-one as we go through C4.

+++ Preliminaries

> The project SHALL use the git distributed revision control system.

Git has its faults. Its command-line API is horribly inconsistent, and it has a complex, messy internal model that it shoves in your face at the slightest provocation. But despite doing its best to make its users feel stupid, git does its job really, really well. More pragmatically, I've found that if you stay away from certain areas (branches!), people learn git rapidly and don't make many mistakes. That works for me.

> The project SHALL be hosted on github.com or equivalent, herein called the "Platform".

I'm sure one day some large firm will buy GitHub and break it, and another platform will rise in its place. Until then, Github serves up a near-perfect set of minimal, fast, simple tools. I've thrown hundreds of people at it, and they all stick like flies stuck in a dish of honey.

> The project SHALL use the Platform issue tracker.

We made the mistake in {{libzmq}} of switching to Jira because we hadn't learned yet how to properly use the GitHub issue tracker. Jira is a great example of how to turn something useful into a complex mess because the business depends on selling more "features". But even without criticizing Jira, keeping the issue tracker on the same platform means one less UI to learn, one less login, and smooth integration between issues and patches.

> The project SHOULD have clearly documented guidelines for code style.

This is a protocol plug-in: insert code style guidelines here. If you don't document the code style you use, you have no basis except prejudice to reject patches.

> A "Contributor" is a person who wishes to provide a patch, being a set of commits that solve some clearly identified problem.
> A "Maintainer" is a person who merge patches to the project. Maintainers are not developers; their job is to enforce process.

Now we move on to definitions of the parties, and the splitting of roles that saved us from the sin of structural dependency on rare individuals. This worked well in {{libzmq}}, but as you will see it depends on the rest of the process. C4 isn't a buffet; you will need the whole process (or something very like it), or it won't hold together.

> Contributors SHALL NOT have commit access to the repository unless they are also Maintainers.
> Maintainers SHALL have commit access to the repository.

What we wanted to avoid was people pushing their changes directly to master. This was the biggest source of trouble in {{libzmq}} historically: large masses of raw code that took months or years to fully stabilize. We eventually followed other 0MQ projects like PyZMQ in using pull requests. We went further, and stipulated that //all// changes had to follow the same path. No exceptions for "special people".

> Everyone, without distinction or discrimination, SHALL have an equal right to become a Contributor under the terms of this contract.

We had to state this explicitly. It used to be that the {{libzmq}} maintainers would reject patches simply because they didn't like them. Now, that may sound reasonable to the author of a library (though {{libzmq}} was not written by any one person), but let's remember our goal of creating a work that is owned by as many people as possible. Saying "I don't like your patch so I'm going to reject it" is equivalent to saying, "I claim to own this and I think I'm better than you, and I don't trust you". Those are toxic messages to give to others who are thinking of becoming your co-investors.

I think this fight between individual expertise and collective intelligence plays out in other areas. It defined Wikipedia, and still does, a decade after that work surpassed anything built by small groups of experts. For me, we make software by slowly synthesizing the most accurate knowledge, much as we make Wikipedia articles.

+++ Licensing and Ownership

> The project SHALL use the GPLv3 or a variant thereof (LGPL, AGPL).

I've already explained how full remixability creates better scale and why the GPL and its variants seems the optimal contract for remixable software. If you're a large business aiming to dump code on the market, you won't want C4, but then you won't really care about community either.

> All contributions to the project source code ("patches") SHALL use the same license as the project.

This removes the need for any specific license or contribution agreement for patches. You fork the GPL code, you publish your remixed version on GitHub, and you or anyone else can then submit that as a patch to the original code. BSD doesn't allow this. Any work that contains BSD code may also contain unlicensed proprietary code so you need explicit action from the author of the code before you can remix it.

> All patches are owned by their authors. There SHALL NOT be any copyright assignment process.

Here we come to the key reason people trust their investments in 0MQ: it's logistically impossible to buy the copyrights to create a closed source competitor to 0MQ. iMatix can't do this either. And the more people that send patches, the harder it becomes. 0MQ isn't just free and open today--this specific rule means it will remain so forever. Note that it's not the case in all GPL projects, many of which still ask for copyright transfer back to the maintainers.

> The project SHALL be owned collectively by all its Contributors.

This is perhaps redundant, but worth saying: if everyone owns their patches, then the resulting whole is also owned by every contributor. There's no legal concept of owning lines of code: the "work" is at least a source file.

> Each Contributor SHALL be responsible for identifying themselves in the project Contributor list.

In other words, the maintainers are not karma accountants. Anyone who wants credit has to claim it themselves.

+++ Patch Requirements

In this section, we define the obligations of the contributor: specifically, what constitutes a "valid" patch, so that maintainers have rules they can use to accept or reject patches.

> Maintainers and Contributors MUST have a Platform account and SHOULD use their real names or a well-known alias.

In the worst case scenario, where someone has submitted toxic code (patented, or owned by someone else), we need to be able to trace who and when, so we can remove the code. Asking for real names or a well-known alias is a theoretical strategy for reducing the risk of bogus patches. We don't know if this actually works because we haven't had the problem yet.

> A patch SHOULD be a minimal and accurate answer to exactly one identified and agreed problem.

This implements the Simplicity Oriented Design process that I'll come to later in this chapter. One clear problem, one minimal solution, apply, test, repeat.

> A patch MUST adhere to the code style guidelines of the project if these are defined.

This is just sanity. I've spent time cleaning up other peoples' patches because they insisted on putting the {{else}} beside the {{if}} instead of just below as Nature intended. Consistent code is healthier.

> A patch MUST adhere to the "Evolution of Public Contracts" guidelines defined below.

Ah, the pain, the pain. I'm not speaking of the time at age eight when I stepped on a plank with a 4-inch nail protruding from it. That was relatively OK. I'm speaking of 2010-2011 when we had multiple parallel releases of 0MQ, each with different //incompatible// APIs or wire protocols. It was an exercise in bad rules, pointlessly enforced, that still hurts us today. The rule was, "If you change the API or protocol, you SHALL create a new major version". Give me the nail through the foot; that hurt less.

One of the big changes we made with C4 was simply to ban, outright, this kind of sanctioned sabotage. Amazingly, it's not even hard. We just don't allow the breaking of existing public contracts, period, unless everyone agrees, in which case no period. As Linus Torvalds famously put it on 23 December 2012, "WE DO NOT BREAK USERSPACE!"

> A patch SHALL NOT include nontrivial code from other projects unless the Contributor is the original author of that code.

This rule has two effects. The first is that it forces people to make minimal solutions because they cannot simply import swathes of existing code. In the cases where I've seen this happen to projects, it's always bad unless the imported code is very cleanly separated. The second is that it avoids license arguments. You write the patch, you are allowed to publish it as LGPL, and we can merge it back in. But you find a 200-line code fragment on the web, and try to paste that, we'll refuse.

> A patch MUST compile cleanly and pass project self-tests on at least the principle target platform.

For cross-platform projects, it is fair to ask that the patch works on the development box used by the contributor.

> A patch commit message SHOULD consist of a single short (less than 50 character) line summarizing the change, optionally followed by a blank line and then a more thorough description. 

This is a good format for commit messages that fits into email (the first line becomes the subject, and the rest becomes the email body).

> A "Correct Patch" is one that satisfies the above requirements.

Just in case it wasn't clear, we're back to legalese and definitions.

+++ Development Process

In this section, we aim to describe the actual development process, step-by-step.

> Change on the project SHALL be governed by the pattern of accurately identifying problems and applying minimal, accurate solutions to these problems.

This is a unapologetic ramming through of thirty years' software design experience. It's a profoundly simple approach to design: make minimal, accurate solutions to real problems, nothing more or less. In 0MQ, we don't have feature requests. Treating new features the same as bugs confuses some newcomers. But this process works, and not just in open source. Enunciating the problem we're trying to solve, with every single change, is key to deciding whether the change is worth making or not.

> To initiate changes, a user SHALL log an issue on the project Platform issue tracker.

This is meant to stop us from going offline and working in a ghetto, either by ourselves or with others. Although we tend to accept pull requests that have clear argumentation, this rule lets us say "stop" to confused or too-large patches.

> The user SHOULD write the issue by describing the problem they face or observe.

"Problem: we need feature X. Solution: make it" is not a good issue. "Problem: user cannot do common tasks A or B except by using a complex workaround. Solution: make feature X" is a decent explanation. Because everyone I've ever worked with has needed to learn this, it seems worth restating: document the real problem first, solution second.

> The user SHOULD seek consensus on the accuracy of their observation, and the value of solving the problem.

And because many apparent problems are illusionary, by stating the problem explicitly we give others a chance to correct our logic. "You're only using A and B a lot because function C is unreliable. Solution: make function C work properly."

> Users SHALL NOT log feature requests, ideas, suggestions, or any solutions to problems that are not explicitly documented and provable.

There are several reasons for not logging ideas, suggestions, or feature requests. In our experience, these just accumulate in the issue tracker until someone deletes them. But more profoundly, when we treat all change as problem solutions, we can prioritize trivially. Either the problem is real and someone wants to solve it now, or it's not on the table. Thus, wish lists are off the table.

> Thus, the release history of the project SHALL be a list of meaningful issues logged and solved.

I'd love the GitHub issue tracker to simply list all the issues we solved in each release. Today we still have to write that by hand. If one puts the issue number in each commit, and if one uses the GitHub issue tracker, which we sadly don't yet do for 0MQ, this release history is easier to produce mechanically.

> To work on an issue, a Contributor SHALL fork the project repository and then work on their forked repository.

Here we explain the GitHub fork + pull request model so that newcomers only have to learn one process (C4) in order to contribute.

> To submit a patch, a Contributor SHALL create a Platform pull request back to the project.

GitHub has made this so simple that we don't need to learn git commands to do it, for which I'm deeply grateful. Sometimes, I'll tell people who I don't particularly like that command-line git is awesome and all they need to do is learn git's internal model in detail before trying to use it on real work. When I see them several months later they look... changed.

> A Contributor SHALL NOT commit changes directly to the project.

Anyone who submits a patch is a contributor, and all contributors follow the same rules. No special privileges to the original authors, because otherwise we're not building a community, only boosting our egos.

> To discuss a patch, people MAY comment on the Platform pull request, on the commit, or elsewhere.

Randomly distributed discussions may be confusing if you're walking up for the first time, but GitHub solves this for all current participants by sending emails to those who need to follow what's going on. We had the same experience and the same solution in Wikidot, and it works. There's no evidence that discussing in different places has any negative effect.

> To accept or reject a patch, a Maintainer SHALL use the Platform interface.

Working via the GitHub web user interface means pull requests are logged as issues, with workflow and discussion. I'm sure there are more complex ways to work. Complexity is easy; it's simplicity that's incredibly hard.

> Maintainers SHALL NOT accept their own patches.

There was a rule we defined in the FFII years ago to stop people burning out: no less than two people on any project. One-person projects tend to end in tears, or at least bitter silence. We have quite a lot of data on burnout, why it happens, and how to prevent it (even cure it). I'll explore this later in the chapter, because if you work with or on open source you need to be aware of the risks. The "no merging your own patch" rule has two goals. First, if you want your project to be C4-certified, you have to get at least one other person to help. If no one wants to help you, perhaps you need to rethink your project. Second, having a control for every patch makes it much more satisfying, keeps us more focused, and stops us breaking the rules because we're in a hurry, or just feeling lazy.

> Maintainers SHALL NOT make value judgments on correct patches.

We already said this but it's worth repeating: the role of Maintainer is not to judge a patch's substance, only its technical quality. The substantive worth of a patch only emerges over time: people use it, and like it, or they do not. And if no one is using a patch, eventually it'll annoy someone else who will remove it, and no one will complain.

> Maintainers SHALL merge correct patches rapidly.

There is a criteria I call //change latency//, which is the round-trip time from identifying a problem to testing a solution. The faster the better. If maintainers cannot respond to pull requests as rapidly as people expect, they're not doing their job (or they need more hands).

> The Contributor MAY tag an issue as "Ready" after making a pull request for the issue.

By default, GitHub offers the usual variety of issues, but with C4 we don't use them. Instead, we need just two labels, "Urgent" and "Ready". A contributor who wants another user to test an issue can then label it as "Ready".

> The user who created an issue SHOULD close the issue after checking the patch is successful.

When one person opens an issue, and another works on it, it's best to allow the original person to close the issue. That acts as a double-check that the issue was properly resolved.

> Maintainers SHOULD ask for improvements to incorrect patches and SHOULD reject incorrect patches if the Contributor does not respond constructively.

Initially, I felt it was worth merging all patches, no matter how poor. There's an element of trolling involved. Accepting even obviously bogus patches could, I felt, pull in more contributors. But people were uncomfortable with this so we defined the "correct patch" rules, and the Maintainer's role in checking for quality. On the negative side, I think we didn't take some interesting risks, which could have paid off with more participants. On the positive side, this has led to {{libzmq}} master (and in all projects that use C4) being practically production quality, practically all the time.

> Any Contributor who has value judgments on a correct patch SHOULD express these via their own patches.

In essence, the goal here is to allow users to try patches rather than to spend time arguing pros and cons. As easy as it is to make a patch, it's as easy to revert it with another patch. You might think this would lead to "patch wars", but that hasn't happened. We've had a handful of cases in {{libzmq}} where patches by one contributor were killed by another person who felt the experimentation wasn't going in the right direction. It is easier than seeking up-front consensus.

> Maintainers MAY commit changes to non-source documentation directly to the project.

This exit allows maintainers who are making release notes to push those without having to create an issue which would then affect the release notes, leading to stress on the space time fabric and possibly involuntary rerouting backwards in the fourth dimension to before the invention of cold beer. Shudder. It is simpler to agree that release notes aren't technically software.

+++ Creating Stable Releases

We want some guarantee of stability for a production system. In the past, this meant taking unstable code and then over months hammering out the bugs and faults until it was safe to trust. iMatix's job, for years, has been to do this to {{libzmq}}, turning raw code into packages by allowing only bug fixes and no new code into a "stabilization branch". It's surprisingly not as thankless as it sounds.

Now, since we went full speed with C4, we've found that git master of {{libzmq}} is mostly perfect, most of the time. This frees our time to do more interesting things, such as building new open source layers on top of {{libzmq}}. However, people still want that guarantee: many users will simply not install except from an "official" release. So a stable release today means two things. First, a snapshot of the master taken at a time when there were no new changes for a while, and no dramatic open bugs. Second, a way to fine tune that snapshot to fix the critical issues remaining in it.

This is the process we explain in this section.

> The project SHALL have one branch ("master") that always holds the latest in-progress version and SHOULD always build.

This is redundant because every patch always builds but it's worth restating. If the master doesn't build (and pass its tests), someone needs waking up.

> The project SHALL NOT use topic branches for any reason. Personal forks MAY use topic branches.

I'll come to branches soon. In short (or "tl;dr", as they say on the webs), branches make the repository too complex and fragile, and require up-front agreement, all of which are expensive and avoidable.

> To make a stable release someone SHALL fork the repository by copying it and thus become maintainer of this repository.
> Forking a project for stabilization MAY be done unilaterally and without agreement of project maintainers.

It's free software. No one has a monopoly on it. If you think the maintainers aren't producing stable releases right, fork the repository and do it yourself. Forking isn't a failure, it's an essential tool for competition. You can't do this with branches, which means a branch-based release policy gives the project maintainers a monopoly. And that's bad because they'll become lazier and more arrogant than if real competition is chasing their heels.

> A stabilization project SHOULD be maintained by the same process as the main project.

Stabilization projects have maintainers and contributors like any project. In practice we usually cherry pick patches from the main project to the stabilization project, but that's just a convenience.

> A patch to a repository declared "stable" SHALL be accompanied by a reproducible test case.

Beware of a one-size-fits-all process. New code does not need the same paranoia as code that people are trusting for production use. In the normal development process, we did not mention test cases. There's a reason for this. While I love testable patches, many changes aren't easily or at all testable. However, to stabilize a code base you want to fix only serious bugs, and you want to be 100% sure every change is accurate. This means before and after tests for every change.

+++ Evolution of Public Contracts

By "public contracts", I mean APIs and protocols. Up until the end of 2011, {{libzmq}}'s naturally happy state was marred by broken promises and broken contracts. We stopped making promises (aka "road maps") for {{libzmq}} completely, and our dominant theory of change is now that it emerges carefully and accurately over time. At a 2012 Chicago meetup, Garrett Smith and Chuck Remes called this the "drunken stumble to greatness", which is how I think of it now.

We stopped breaking public contracts simply by banning the practice. Before then it had been "OK" (as in we did it and everyone complained bitterly, and we ignored them) to break the API or protocol so long as we changed the major version number. Sounds fine, until you get 0MQ v2.0, v3.0, and v4.0 all in development at the same time, and not speaking to each other.

> All Public Contracts (APIs or protocols) SHOULD be documented.

You'd think this was a given for professional software engineers but no, it's not. So, it's a rule. You want C4 certification for your project, you make sure your public contracts are documented. No "It's specified in the code" excuses. Code is not a contract. (Yes, I intend at some point to create a C4 certification process to act as a quality indicator for open source projects.)

> All Public Contracts SHALL use Semantic Versioning.

This rule is mainly here because people asked for it. I've no real love for it, as Semantic Versioning is what led to the so-called "Why does 0MQ not speak to itself?!" debacle. I've never seen the problem that this solved. Something about runtime validation of library versions, or some-such.

> All Public Contracts SHOULD have space for extensibility and experimentation.

Now, the real thing is that public contracts //do change//. It's not about not changing them. It's about changing them safely. This means educating (especially protocol) designers to create that space up-front.

> A patch that modifies a stable Public Contract SHOULD not break existing applications unless there is overriding consensus on the value of doing this.

Sometimes the patch is fixing a bad API that no one is using. It's a freedom we need, but it should be based on consensus, not one person's dogma. However, making random changes "just because" is not good. In 0MQ v3.x, did we benefit from renaming {{ZMQ_NOBLOCK}} to {{ZMQ_DONTWAIT}}? Sure, it's closer to the POSIX socket {{recv()}} call, but is that worth breaking thousands of applications? No one ever reported it as an issue. To misquote Stallman: "your freedom to create an ideal world stops one inch from my application."

> A patch that introduces new features to a Public Contract SHOULD do so using new names.

We had the experience in 0MQ once or twice of new features using old names (or worse, using names that were //still in use// elsewhere). 0MQ v3.0 had a newly introduced "ROUTER" socket that was totally different from the existing ROUTER socket in 2.x. Dear lord, you should be face-palming, why? The reason: apparently, even smart people sometimes need regulation to stop them doing silly things.

> Old names SHOULD be deprecated in a systematic fashion by marking new names as "experimental" until they are stable, then marking the old names as "deprecated".

This life cycle notation has the great benefit of actually telling users what is going on with a consistent direction. "Experimental" means "we have introduced this and intend to make it stable if it works". It does not mean, "we have introduced this and will remove it at any time if we feel like it". One assumes that code that survives more than one patch cycle is meant to be there. "Deprecated" means "we have replaced this and intend to remove it".

> When sufficient time has passed, old deprecated names SHOULD be marked "legacy" and eventually removed.

In theory this gives applications time to move onto stable new contracts without risk. You can upgrade first, make sure things work, and then, over time, fix things up to remove dependencies on deprecated and legacy APIs and protocols.

> Old names SHALL NOT be reused by new features.

Ah, yes, the joy when 0MQ v3.x renamed the top-used API functions ({{zmq_send[3]}} and {{zmq_recv[3]}}) and then recycled the old names for new methods that were utterly incompatible (and which I suspect few people actually use). You should be slapping yourself in confusion again, but really, this is what happened and I was as guilty as anyone. After all, we did change the version number! The only benefit of that experience was to get this rule.

> When old names are removed, their implementations MUST provoke an exception (assertion) if used by applications.

I've not tested this rule to be certain it makes sense. Perhaps what it means is "if you can't provoke a compile error because the API is dynamic, provoke an assertion".

+++ Project Administration

> The project founders SHALL act as Administrators to manage the set of project Maintainers.

Someone needs to administer the project, and it makes sense that the original founders start this ball rolling.

> The Administrators SHALL ensure their own succession over time by promoting the most effective Maintainers.

At the same time, as founder of a project you really want to get out of the way before you become over-attached to it. Promoting the most active and consistent maintainers is good for everyone.

> A new Contributor who makes a correct patch SHALL be invited to become a Maintainer.

I met Felix Geisendörfer in Lyons in 2012 at the [http://www.mix-it.fr Mix-IT conference] where I presented Social Architecture and one thing that came out of this was Felix's now famous [http://felixge.de/2013/03/11/the-pull-request-hack.html Pull Request Hack]. It fits elegantly into C4 and solves the problem of maintainers dropping out over time.

> Administrators MAY remove Maintainers who are inactive for an extended period of time, or who repeatedly fail to apply this process accurately.

This was Ian Barber's suggestion: we need a way to crop inactive maintainers. Originally maintainers were self-elected but that makes it hard to drop troublemakers (who are rare, but not unknown).

C4 is not perfect. Few things are. The process for changing it (Digistan's COSS) is a little outdated now: it relies on a single-editor workflow with the ability to fork, but not merge. This seems to work but it could be better to use C4 for protocols like C4.

++ A Real-Life Example

In [http://lists.zeromq.org/pipermail/zeromq-dev/2012-October/018838.html this email thread], Dan Goes asks how to make a publisher that knows when a new client subscribes, and sends out previous matching messages. It's a standard pub-sub technique called "last value caching". Now over a 1-way transport like pgm (where subscribers literally send no packets back to publishers), this can't be done. But over TCP, it can, if we use an XPUB socket and if that socket didn't cleverly filter out duplicate subscriptions to reduce upstream traffic.

Though I'm not an expert contributor to {{libzmq}}, this seems like a fun problem to solve. How hard could it be? I start by forking the {{libzmq}} repository to my own GitHub account and then clone it to my laptop, where I build it:

[[code]]
git clone git@github.com:hintjens/libzmq.git
cd libzmq
./autogen.sh
./configure
make
[[/code]]

Because the {{libzmq}} code is neat and well-organized, it was quite easy to find the main files to change ({{xpub.cpp}} and {{xpub.hpp}}). Each socket type has its own source file and class. They inherit from {{socket_base.cpp}}, which has this hook for socket-specific options:

[[code]]
//  First, check whether specific socket type overloads the option.
int rc = xsetsockopt (option_, optval_, optvallen_);
if (rc == 0 || errno != EINVAL)
    return rc;

//  If the socket type doesn't support the option, pass it to
//  the generic option parser.
return options.setsockopt (option_, optval_, optvallen_);
[[/code]]

Then I check where the XPUB socket filters out duplicate subscriptions, in its {{xread_activated}} method:

[[code]]
bool unique;
if (*data == 0)
    unique = subscriptions.rm (data + 1, size - 1, pipe_);
else
    unique = subscriptions.add (data + 1, size - 1, pipe_);

//  If the subscription is not a duplicate store it so that it can be
//  passed to used on next recv call.
if (unique && options.type != ZMQ_PUB)
    pending.push_back (blob_t (data, size));
[[/code]]

At this stage, I'm not too concerned with the details of how {{subscriptions.rm}} and {{subscriptions.add}} work. The code seems obvious except that "subscription" also includes unsubscription, which confused me for a few seconds. If there's anything else weird in the rm and add methods, that's a separate issue to fix later. Time to make an issue for this change. I head over to the {{zeromq.jira.com}} site, log in, and create a new entry.

Jira kindly offers me the traditional choice between "bug" and "new feature" and I spend thirty seconds wondering where this counterproductive historical distinction came from. Presumably, the "we'll fix bugs for free, but you pay for new features" commercial proposal, which stems from the "you tell us what you want and we'll make it for $X" model of software development, and which generally leads to "we spent three times $X and we got what?!" email Fists of Fury.

Putting such thoughts aside, I create [https://zeromq.jira.com/browse/LIBZMQ-443 an issue #443] and described the problem and plausible solution:

> Problem: XPUB socket filters out duplicate subscriptions (deliberate design). However this makes it impossible to do subscription-based intelligence. See http://lists.zeromq.org/pipermail/zeromq-dev/2012-October/018838.html for a use case.
> Solution: make this behavior configurable with a socket option.

It's naming time. The API sits in {{include/zmq.h}}, so this is where I added the option name. When you invent a concept in an API or anywhere, //please// take a moment to choose a name that is explicit and short and obvious. Don't fall back on generic names that need additional context to understand. You have one chance to tell the reader what your concept is and does. A name like {{ZMQ_SUBSCRIPTION_FORWARDING_FLAG}} is terrible. It technically kind of aims in the right direction, but is miserably long and obscure. I chose {{ZMQ_XPUB_VERBOSE}}: short and explicit and clearly an on/off switch with "off" being the default setting.

So, it's time to add a private property to the {{xpub}} class definition in {{xpub.hpp}}:

[[code]]
// If true, send all subscription messages upstream, not just
// unique ones
bool verbose;
[[/code]]

And then lift some code from {{router.cpp}} to implement the {{xsetsockopt}} method. Finally, change the {{xread_activated}} method to use this new option, and while at it, make that test on socket type more explicit too:

[[code]]
//  If the subscription is not a duplicate store it so that it can be
//  passed to used on next recv call.
if (options.type == ZMQ_XPUB && (unique || verbose))
    pending.push_back (blob_t (data, size));
[[/code]]

The thing builds nicely the first time. This makes me a little suspicious, but being lazy and jet-lagged I don't immediately make a test case to actually try out the change. The process doesn't demand that, even if usually I'd do it just to catch that inevitable 10% of mistakes we all make. I do however document this new option on the {{doc/zmq_setsockopt.txt}} man page. In the worst case, I added a patch that wasn't really useful. But I certainly didn't break anything.

I don't implement a matching {{zmq_getsockopt}} because "minimal" means what it says. There's no obvious use case for getting the value of an option that you presumably just set, in code. Symmetry isn't a valid reason to double the size of a patch. I did have to document the new option because the process says, "All Public Contracts SHOULD be documented."

Committing the code, I push the patch to my forked repository (the "origin"):

[[code]]
git commit -a -m "Fixed issue #443"
git push origin master
[[/code]]

Switching to the GitHub web interface, I go to my {{libzmq}} fork, and press the big "Pull Request" button at the top. GitHub asks me for a title, so I enter "Added ZMQ_XPUB_VERBOSE option". I'm not sure why it asks this as I made a neat commit message but hey, let's go with the flow here.

This makes a nice little pull request with two commits; the one I'd made a month ago on the release notes to prepare for the v3.2.1 release (a month passes so quickly when you spend most of it in airports), and my fix for issue #443 (37 new lines of code). GitHub lets you continue to make commits after you've kicked off a pull request. They get queued up and merged in one go. That is easy, but the maintainer may refuse the whole bundle based on one patch that doesn't look valid.

Because Dan is waiting (at least in my highly optimistic imagination) for this fix, I go back to the zeromq-dev list and tell him I've made the patch, with a link to the commit. The faster I get feedback, the better. It's 1 a.m. in South Korea as I make this patch, so early evening in Europe, and morning in the States. You learn to count timezones when you work with people across the world. Ian is in a conference, Mikko is getting on a plane, and Chuck is probably in the office, but three hours later, Ian merges the pull request.

After Ian merges the pull request, I resynchronize my fork with the upstream {{libzmq}} repository. First, I add a //remote// that tells git where this repository sits (I do this just once in the directory where I'm working):

[[code]]
git remote add upstream git://github.com/zeromq/libzmq.git
[[/code]]

And then I pull changes back from the upstream master and check the git log to double-check:

[[code]]
git pull --rebase upstream master
git log
[[/code]]

And that is pretty much it, in terms of how much git one needs to learn and use to contribute patches to {{libzmq}}. Six git commands and some clicking on web pages. Most importantly to me as a naturally lazy, stupid, and easily confused developer, I don't have to learn git's internal models, and never have to do anything involving those infernal engines of structural complexity we call "git branches". Next up, the attempted assassination of git branches. Let's live dangerously!

++ Git Branches Considered Harmful

One of git's most popular features is its branches. Almost all projects that use git use branches, and the selection of the "best" branching strategy is like a rite of passage for an open source project. Vincent Driessen's [http://nvie.com/posts/a-successful-git-branching-model/ git-flow] may be the best known. It has //base// branches (master, develop), //feature// branches, //release// branches, //hotfix// branches, and //support// branches. Many teams have adopted git-flow, which even has git extensions to support it. I'm a great believer in popular wisdom, but sometimes you have to recognize mass delusion for what it is.

Here is a section of C4 that might have shocked you when you first read it:

> The project SHALL NOT use topic branches for any reason. Personal forks MAY use topic branches.

To be clear, it's //public branches in shared repositories// that I'm talking about. Using branches for private work, e.g., to work on different issues, appears to work well enough, though it's more complexity than I personally enjoy. To channel Stallman again: "your freedom to create complexity ends one inch from our shared workspace."

Like the rest of C4, the rules on branches are not accidental. They came from our experience making 0MQ, starting when Martin Sustrik and I rethought how to make stable releases. We both love and appreciate simplicity (some people seem to have a remarkable tolerance for complexity). We chatted for a while... I asked him, "I'm going to start making a stable release. Would it be OK for me to make a branch in the git you're working in?" Martin didn't like the idea. "OK, if I fork the repository, I can move patches from your repo to that one". That felt much better to both of us.

The response from many in the 0MQ community was shock and horror. People felt we were being lazy and making contributors work harder to find the "right" repository. Still, this seemed simple, and indeed it worked smoothly. The best part was that we each worked as we wanted to. Whereas before, the 0MQ repository had felt horribly complex (and it wasn't even anything like git-flow), this felt simple. And it worked. The only downside was that we lost a single unified history. Now, perhaps historians will feel robbed, but I honestly can't see that the historical minutiae of who changed what, when, including every branch and experiment, are worth any significant pain or friction.

People have gotten used to the "multiple repositories" approach in ZeroMQ and we've started using that in other projects quite successfully. My own opinion is that history will judge git branches and patterns like git-flow as a complex solution to imaginary problems inherited from the days of Subversion and monolithic repositories.

More profoundly, and perhaps this is why the majority seems to be "wrong": I think the the branches versus forks argument is really a deeper design versus evolve argument about how to make software optimally. I'll address that deeper argument in the next section. For now, I'll try to be scientific about my irrational hatred of branches, by looking at a number of criteria, and comparing branches and forks in each one.

+++ Simplicity Versus Complexity

//The simpler, the better.//

There is no inherent reason why branches are more complex than forks. However, git-flow uses //five types// of branch, whereas C4 uses two types of fork (development, and stable) and one branch (master). Circumstantial evidence is thus that branches lead to more complexity than forks. For new users, it is definitely, and we've measured this in practice, easier to learn to work with many repositories and no branches except master.

+++ Change Latency

//The smaller and more rapid the delivery, the better.//

Development branches seem to correlate strongly with large, slow, risky deliveries. "Sorry, I have to merge this branch before we can test the new version" signals a breakdown in process. It's certainly not how C4 works, which is by focusing tightly on individual problems and their minimal solutions. Allowing branches in development raises change latency. Forks have a different outcome: it's up to the forker to ensure that his changes merge cleanly, and to keep them simple so they won't be rejected.

+++ Learning Curve

//The smoother the learning curve, the better.//

Evidence definitely shows that learning to use git branches is complex. For some people, this is OK. For most developers, every cycle spent learning git is a cycle lost on more productive things. I've been told several times, by different people that I do not like branches because I "never properly learned git". That is fair, but it is a criticism of the tool, not the human.

+++ Cost of Failure

//The lower the cost of failure, the better.//

Branches demand more perfection from developers because mistakes potentially affect others. This raises the cost of failure. Forks make failure extremely cheap because literally nothing that happens in a fork can affect others not using that fork.

+++ Up-front Coordination

//The less need for up-front coordination, the better.//

You can do a hostile fork. You cannot do a hostile branch. Branches depend on up-front coordination, which is expensive and fragile. One person can veto the desires of a whole group. For example in the 0MQ community we were unable to agree on a git branching model for a year. We solved that by using forking instead. The problem went away.

+++ Scalability

//The more you can scale a project, the better.//

The strong assumption in all branch strategies is that the repository //is// the project. But there is a limit to how many people you can get to agree to work together in one repository. As I explained, the cost of up-front coordination can become fatal. A more realistic project scales by allowing anyone to start their own repositories, and ensuring these can work together. A project like 0MQ has dozens of repositories. Forking looks more scalable than branching.

+++ Surprise and Expectations

//The less surprising, the better.//

People expect branches and find forks to be uncommon and thus confusing. This is the one aspect where branches win. If you use branches, a single patch will have the same commit hash tag, whereas across forks the patch will have different hash tags. That makes it harder to track patches as they cross forks, true. But seriously, //having to track hexadecimal hash tags is not a feature//. It's a bug. Sometimes better ways of working are surprising at first.

+++ Economics of Participation

//The more tangible the rewards, the better.//

People like to own their work and get credit for it. This is much easier with forks than with branches. Forks create more competition in a healthy way, while branches suppress competition and force people to collaborate and share credit. This sounds positive but in my experience it demotivates people. A branch isn't a product you can "own", whereas a fork can be.

+++ Robustness in Conflict

//The more a model can survive conflict, the better.//

Like it or not, people fight over ego, status, beliefs, and theories of the world. Challenge is a necessary part of science. If your organizational model depends on agreement, you won't survive the first real fight. Branches do not survive real arguments and fights, whereas forks can be hostile, and still benefit all parties. And this is indeed how free software works.

+++ Guarantees of Isolation

//The stronger the isolation between production code and experiment, the better.//

People make mistakes. I've seen experimental code pushed to mainline production by error. I've seen people make bad panic changes under stress. But the real fault is in allowing two entirely separate generations of product to exist in the same protected space. If you can push to random-branch-x, you can push to master. Branches do not guarantee isolation of production critical code. Forks do.

+++ Visibility

//The more visible our work, the better.//

Forks have watchers, issues, a README, and a wiki. Branches have none of these. People try forks, build them, break them, patch them. Branches sit there until someone remembers to work on them. Forks have downloads and tarballs. Branches do not. When we look for self-organization, the more visible and declarative the problems, the faster and more accurately we can work.

+++ Conclusions

In this section, I've listed a series of arguments, most of which came from fellow team members. Here's how it seems to break down: git veterans insist that branches are the way to work, whereas newcomers tend to feel intimidated when asked to navigate git branches. Git is not an easy tool to master. What we've discovered, accidentally, is that when you stop using branches //at all//, git becomes trivial to use. It literally comes down to six commands ({{clone}}, {{remote}}, {{commit}}, {{log}}, {{push}}, and {{pull}}). Furthermore, a branch-free process actually works, we've used it for a couple of years now, and no visible downside except surprise to the veterans and growth of "single" projects over multiple repositories.

If you can't use forks, perhaps because your firm doesn't trust GitHub's private repositories, then you can perhaps use topic branches, one per issue. You'll still suffer the costs of getting up-front consensus, low competitiveness, and risk of human error.

++ Designing for Innovation

Let's look at innovation, which Wikipedia defines as, "the development of new values through solutions that meet new requirements, inarticulate needs, or old customer and market needs in value adding new ways." This really just means solving problems more cheaply. It sounds straight-forward, but the history of collapsed tech giants proves that it's not. I'll try to explain how teams so often get it wrong, and suggest a way for doing innovation right.

+++ The Tale of Two Bridges

Two old engineers were talking of their lives and boasting of their greatest projects. One of the engineers explained how he had designed one of the greatest bridges ever made.

"We built it across a river gorge," he told his friend. "It was wide and deep. We spent two years studying the land, and choosing designs and materials. We hired the best engineers and designed the bridge, which took another five years. We contracted the largest engineering firms to build the structures, the towers, the tollbooths, and the roads that would connect the bridge to the main highways. Dozens died during the construction. Under the road level we had trains, and a special path for cyclists. That bridge represented years of my life."

The second man reflected for a while, then spoke. "One evening me and a friend got drunk on vodka, and we threw a rope across a gorge," he said. "Just a rope, tied to two trees. There were two villages, one at each side. At first, people pulled packages across that rope with a pulley and string. Then someone threw a second rope, and built a foot walk. It was dangerous, but the kids loved it. A group of men then rebuilt that, made it solid, and women started to cross, everyday, with their produce. A market grew up on one side of the bridge, and slowly that became a large town, because there was a lot of space for houses. The rope bridge got replaced with a wooden bridge, to allow horses and carts to cross. Then the town built a real stone bridge, with metal beams. Later, they replaced the stone part with steel, and today there's a suspension bridge standing in that same spot."

The first engineer was silent. "Funny thing," he said, "my bridge was demolished about ten years after we built it. Turns out it was built in the wrong place and no one wanted to use it. Some guys had thrown a rope across the gorge, a few miles further downstream, and that's where everyone went."

+++ How 0MQ Lost Its Road Map

Presenting 0MQ at the Mix-IT conference in Lyon in early 2012, I was asked several times for the "road map". My answer was: there is no road map any longer. We had road maps, and we deleted them. Instead of a few experts trying to lay out the next steps, we were allowing this to happen organically. The audience didn't really like my answer. So un-French.

However, the history of 0MQ makes it quite clear why road maps were problematic. In the beginning, we had a small team making the library, with few contributors, and no documented road map. As 0MQ grew more popular and we switched to more contributors, users asked for road maps. So we collected our plans together and tried to organize them into releases. Here, we wrote, is what will come in the next release.

As we rolled out releases, we hit the problem that it's very easy to promise stuff, and rather harder to make it as planned. For one thing, much of the work was voluntary, and it's not clear how you force volunteers to commit to a road map. But also, priorities can shift dramatically over time. So we were making promises we could not keep, and the real deliveries didn't match the road maps.

The second problem was that by defining the road map, we in effect claimed territory, making it harder for others to participate. People do prefer to contribute to changes they believe were their idea. Writing down a list of things to do turns contribution into a chore rather than an opportunity.

Finally, we saw changes in 0MQ that were quite traumatic, and the road maps didn't help with this, despite a lot of discussion and effort to "do it right". Examples of this were incompatible changes in APIs and protocols. It was quite clear that we needed a different approach for defining the change process.

Software engineers don't like the notion that powerful, effective solutions can come into existence without an intelligent designer actively thinking things through. And yet no one in that room in Lyon would have questioned evolution. A strange irony, and one I wanted to explore further as it underpins the direction the 0MQ community has taken since the start of 2012.

In the dominant theory of innovation, brilliant individuals reflect on large problem sets and then carefully and precisely create a solution. Sometimes they will have "eureka" moments where they "get" brilliantly simple answers to whole large problem sets. The inventor, and the process of invention are rare, precious, and can command a monopoly. History is full of such heroic individuals. We owe them our modern world.

Looking more closely, however, and you will see that the facts don't match. History doesn't show lone inventors. It shows lucky people who steal or claim ownership of ideas that are being worked on by many. It shows brilliant people striking lucky once, and then spending decades on fruitless and pointless quests. The best known large-scale inventors like Thomas Edison were in fact just very good at systematic broad research done by large teams. It's like claiming that Steve Jobs invented every device made by Apple. It is a nice myth, good for marketing, but utterly useless as practical science.

Recent history, much better documented and less easy to manipulate, shows this well. The Internet is surely one of the most innovative and fast-moving areas of technology, and one of the best documented. It has no inventor. Instead, it has a massive economy of people who have carefully and progressively solved a long series of immediate problems, documented their answers, and made those available to all. The innovative nature of the Internet comes not from a small, select band of Einsteins. It comes from RFCs anyone can use and improve, made by hundreds and thousands of smart, but not uniquely smart, individuals. It comes from open source software anyone can use and improve. It comes from sharing, scale of community, and the continuous accretion of good solutions and disposal of bad ones.

Here thus is an alternative theory of innovation:

# There is an infinite problem/solution terrain.
# This terrain changes over time according to external conditions.
# We can only accurately perceive problems to which we are close.
# We can rank the cost/benefit economics of problems using a market for solutions.
# There is an optimal solution to any solvable problem.
# We can approach this optimal solution heuristically, and mechanically.
# Our intelligence can make this process faster, but does not replace it.

There are a few corollaries to this:

* //Individual creativity matters less than process.// Smarter people may work faster, but they may also work in the wrong direction. It's the collective vision of reality that keeps us honest and relevant.

* //We don't need road maps if we have a good process.// Functionality will emerge and evolve over time as solutions compete for market share.

* //We don't invent solutions so much as discover them.// All sympathies to the creative soul. It's just an information processing machine that likes to polish its own ego and collect karma.

* //Intelligence is a social effect, though it feels personal.// A person cut off from others eventually stops thinking. We can neither collect problems nor measure solutions without other people.

* //The size and diversity of the community is a key factor.// Larger, more diverse communities collect more relevant problems, and solve them more accurately, and do this faster, than a small expert group.

So, when we trust the solitary experts, they make classic mistakes. They focus on ideas, not problems. They focus on the wrong problems. They make misjudgments about the value of solving problems. They don't use their own work.

Can we turn the above theory into a reusable process? In late 2011, I started documenting C4 and similar contracts, and using them both in 0MQ and in closed source projects. The underlying process is something I call "Simplicity Oriented Design", or SOD. This is a reproducible way of developing simple and elegant products. It organizes people into flexible supply chains that are able to navigate a problem landscape rapidly and cheaply. They do this by building, testing, and keeping or discarding minimal plausible solutions, called "patches". Living products consist of long series of patches, applied one atop the other.

SOD is relevant first because it's how we evolve 0MQ. It's also the basis for the design process we will use in [#advanced-architecture] to develop larger-scale 0MQ applications. Of course, you can use any software architecture methodology with 0MQ.

To best understand how we ended up with SOD, let's look at the alternatives.

+++ Trash-Oriented Design

The most popular design process in large businesses seems to be //Trash-Oriented Design//, or TOD. TOD feeds off the belief that all we need to make money are great ideas. It's tenacious nonsense, but a powerful crutch for people who lack imagination. The theory goes that ideas are rare, so the trick is to capture them. It's like non-musicians being awed by a guitar player, not realizing that great talent is so cheap it literally plays on the streets for coins.

The main output of TODs is expensive "ideation": concepts, design documents, and products that go straight into the trash can. It works as follows:

* The Creative People come up with long lists of "we could do X and Y". I've seen endlessly detailed lists of everything amazing a product could do. We've all been guilty of this. Once the creative work of idea generation has happened, it's just a matter of execution, of course.

* So the managers and their consultants pass their brilliant ideas to designers who create acres of preciously refined design documents. The designers take the tens of ideas the managers came up with, and turn them into hundreds of world-changing designs.

* These designs get given to engineers who scratch their heads and wonder who the heck came up with such nonsense. They start to argue back, but the designs come from up high, and really, it's not up to engineers to argue with creative people and expensive consultants.

* So the engineers creep back to their cubicles, humiliated and threatened into building the gigantic but oh-so-elegant junk heap. It is bone-breaking work because the designs take no account of practical costs. Minor whims might take weeks of work to build. As the project gets delayed, the managers bully the engineers into giving up their evenings and weekends.

* Eventually, something resembling a working product makes it out of the door. It's creaky and fragile, complex and ugly. The designers curse the engineers for their incompetence and pay more consultants to put lipstick onto the pig, and slowly the product starts to look a little nicer.

* By this time, the managers have started to try to sell the product and they find, shockingly, that no one wants it. Undaunted, they courageously build million-dollar web sites and ad campaigns to explain to the public why they absolutely need this product. They do deals with other businesses to force the product on the lazy, stupid, and ungrateful market.

* After twelve months of intense marketing, the product still isn't making profits. Worse, it suffers dramatic failures and gets branded in the press as a disaster. The company quietly shelves it, fires the consultants, buys a competing product from a small startup and rebrands that as its own Version 2. Hundreds of millions of dollars end up in the trash.

* Meanwhile, another visionary manager somewhere in the organization drinks a little too much tequila with some marketing people and has a Brilliant Idea.

Trash-Oriented Design would be a caricature if it wasn't so common. Something like 19 out of 20 market-ready products built by large firms are failures (yes, 87% of statistics are made up on the spot). The remaining 1 in 20 probably only succeeds because the competitors are so bad and the marketing is so aggressive.

The main lessons of TOD are quite straightforward but hard to swallow. They are:

* Ideas are cheap. No exceptions. There are no brilliant ideas. Anyone who tries to start a discussion with "oooh, we can do this too!" should be beaten down with all the passion one reserves for traveling evangelists. It is like sitting in a cafe at the foot of a mountain, drinking a hot chocolate and telling others, "Hey, I have a great idea, we can climb that mountain! And build a chalet on top! With two saunas! And a garden! Hey, and we can make it solar powered! Dude, that's awesome! What color should we paint it? Green! No, blue! OK, go and make it, I'll stay here and make spreadsheets and graphics!"

* The starting point for a good design process is to collect real problems that confront real people. The second step is to evaluate these problems with the basic question, "How much is it worth to solve this problem?" Having done that, we can collect that set of problems that are worth solving.

* Good solutions to real problems will succeed as products. Their success will depend on how good and cheap the solution is, and how important the problem is (and sadly, how big the marketing budgets are). But their success will also depend on how much they demand in effort to use--in other words, how simple they are.

Now, after slaying the dragon of utter irrelevance, we attack the demon of complexity.

+++ Complexity-Oriented Design

Really good engineering teams and small firms can usually build decent products. But the vast majority of products still end up being too complex and less successful than they might be. This is because specialist teams, even the best, often stubbornly apply a process I call //Complexity-Oriented Design//, or COD, which works as follows:

* Management correctly identifies some interesting and difficult problem with economic value. In doing so, they already leapfrog over any TOD team.

* The team with enthusiasm starts to build prototypes and core layers. These work as designed and thus encouraged, the team go off into intense design and architecture discussions, coming up with elegant schemas that look beautiful and solid.

* Management comes back and challenges the team with yet more difficult problems. We tend to equate cost with value, so the harder and more expensive to solve, the more the solution should be worth, in their minds.

* The team, being engineers and thus loving to build stuff, build stuff. They build and build and build and end up with massive, perfectly-designed complexity.

* The products go to market, and the market scratches its head and asks, "Seriously, is this the best you can do?" People do use the products, especially if they aren't spending their own money in climbing the learning curve.

* Management gets positive feedback from its larger customers, who share the same idea that high cost (in training and use) means high value, and so continues to push the process.

* Meanwhile somewhere across the world, a small team is solving the same problem using a better process, and a year later smashes the market to little pieces.

COD is characterized by a team obsessively solving the wrong problems in a form of collective delusion. COD products tend to be large, ambitious, complex, and unpopular. Much open source software is the output of COD processes. It is insanely hard for engineers to //stop// extending a design to cover more potential problems. They argue, "What if someone wants to do X?" but never ask themselves, "What is the real value of solving X?"

A good example of COD in practice is Bluetooth, a complex, over-designed set of protocols that users hate. It continues to exist only because in a massively-patented industry there are no real alternatives. Bluetooth is perfectly secure, which is close to pointless for a proximity protocol. At the same time, it lacks a standard API for developers, meaning it's really costly to use Bluetooth in applications.

On the #zeromq IRC channel, Wintre once wrote of how enraged he was many years ago when he "found that XMMS 2 had a working plugin system, but could not actually play music."

COD is a form of large-scale "rabbit-holing", in which designers and engineers cannot distance themselves from the technical details of their work. They add more and more features, utterly misreading the economics of their work.

The main lessons of COD are also simple, but hard for experts to swallow. They are:

* Making stuff that you don't immediately have a need for is pointless. Doesn't matter how talented or brilliant you are, if you just sit down and make stuff people are not actually asking for, you are most likely wasting your time.

* Problems are not equal. Some are simple, and some are complex. Ironically, solving the simpler problems often has more value to more people than solving the really hard ones. So if you allow engineers to just work on random things, they'll mostly focus on the most interesting but least worthwhile things.

* Engineers and designers love to make stuff and decoration, and this inevitably leads to complexity. It is crucial to have a "stop mechanism", a way to set short, hard deadlines that force people to make smaller, simpler answers to just the most crucial problems.

+++ Simplicity Oriented Design

Finally, we come to the rare but precious //Simplicity Oriented Design//, or SOD. This process starts with a realization: we do not know what we have to make until after we start making it. Coming up with ideas or large-scale designs isn't just wasteful, it's a direct hindrance to designing the truly accurate solutions. The really juicy problems are hidden like far valleys, and any activity except active scouting creates a fog that hides those distant valleys. You need to keep mobile, pack light, and move fast.

SOD works as follows:

* We collect a set of interesting problems (by looking at how people use technology or other products) and we line these up from simple to complex, looking for and identifying patterns of use.

* We take the simplest, most dramatic problem and we solve this with a minimal plausible solution, or "patch". Each patch solves exactly a genuine and agreed-upon problem in a brutally minimal fashion.

* We apply one measure of quality to patches, namely "Can this be done any simpler while still solving the stated problem?" We can measure complexity in terms of concepts and models that the user has to learn or guess in order to use the patch. The fewer, the better. A perfect patch solves a problem with zero learning required by the user.

* Our product development consists of a patch that solves the problem "we need a proof of concept" and then evolves in an unbroken line to a mature series of products, through hundreds or thousands of patches piled on top of each other.

* We do not do //anything// that is not a patch. We enforce this rule with formal processes that demand that every activity or task is tied to a genuine and agreed-upon problem, explicitly enunciated and documented.

* We build our projects into a supply chain where each project can provide problems to its "suppliers" and receive patches in return. The supply chain creates the "stop mechanism" because when people are impatiently waiting for an answer, we necessarily cut our work short.

* Individuals are free to work on any projects, and provide patches at any place they feel it's worthwhile. No individuals "own" any project, except to enforce the formal processes. A single project can have many variations, each a collection of different, competing patches.

* Projects export formal and documented interfaces so that upstream (client) projects are unaware of change happening in supplier projects. Thus multiple supplier projects can compete for client projects, in effect creating a free and competitive market.

* We tie our supply chain to real users and external clients and we drive the whole process by rapid cycles so that a problem received from outside users can be analyzed, evaluated, and solved with a patch in a few hours.

* At every moment from the very first patch, our product is shippable. This is essential, because a large proportion of patches will be wrong (10-30%) and only by giving the product to users can we know which patches have become problems that need solving.

SOD is a //hill-climbing algorithm//, a reliable way of finding optimal solutions to the most significant problems in an unknown landscape. You don't need to be a genius to use SOD successfully, you just need to be able to see the difference between the fog of activity and the progress towards new real problems.

People have pointed out that hill-climbing algorithms have known limitations. One gets stuck on local peaks, mainly. But this is nonetheless how life itself works: collecting tiny incremental improvements over long periods of time. There is no intelligent designer. We reduce the risk of local peaks by spreading out widely across the landscape, but it is somewhat moot. The limitations aren't optional, they are physical laws. The theory says, //this is how innovation really works, so better embrace it and work with it than try to work on the basis of magical thinking//.

And in fact once you see all innovation as more or less successful hill-climbing, you realize why some teams and companies and products get stuck in a never-never land of diminishing prospects. They simply don't have the diversity and collective intelligence to find better hills to climb. When Nokia killed their open source projects, they cut their own throat.

A really good designer with a good team can use SOD to build world-class products, rapidly and accurately. To get the most out of SOD the designer has to use the product continuously, from day one, and develop his or her ability to smell out problems such as inconsistency, surprising behavior, and other forms of friction. We naturally overlook many annoyances, but a good designer picks these up and thinks about how to patch them. Design is about removing friction in the use of a product.

In an open source setting, we do this work in public. There's no "let's open the code" moment. Projects that do this are in my view missing the point of open source, which is to engage your users in your exploration, and to build community around the seed of the architecture.

++ Burnout

The 0MQ community has been and still is heavily dependent on pro bono individual efforts. I'd like to think that everyone was compensated in some way for their contributions, and I believe that with 0MQ, contributing means gaining expertise in an extraordinarily valuable technology, which leads to improved professional options.

However, not all projects will be so lucky and if you work with or in open source, you should understand the risk of burnout that volunteers face. This applies to all pro bono communities. In this section, I'll explain what causes burnout, how to recognize it, how to prevent it, and (if it happens) how to try to treat it. Disclaimer: I'm not a psychiatrist and this article is based on my own experiences of working in pro bono contexts for the last 20 years, including free software projects, and NGOs such as the [http://www.ffii.org FFII].

In a pro bono context, we're expected to work without direct or obvious economic incentive. That is, we sacrifice family life, professional advancement, free time, and health in order to accomplish some goal we have decided to accomplish. In any project, we need some kind of reward to make it worth continuing each day. In most pro bono projects the rewards are very indirect, superficially not economical at all. Mostly, we do things because people say, "Hey, great!" Karma is a powerful motivator.

However, we are economic beings, and sooner or later, if a project costs us a great deal and does not bring economic rewards of some kind (money, fame, a new job), we start to suffer. At a certain stage, it seems our subconscious simply gets disgusted and says, "Enough is enough!" and refuses to go any further. If we try to force ourselves, we can literally get sick.

This is what I call "burnout", though the term is also used for other kinds of exhaustion. Too much investment on a project with too little economic reward, for too long. We are great at manipulating ourselves and others, and this is often part of the process that leads to burnout. We tell ourselves that it's for a good cause and that the other guy is doing OK, so we should be able to as well.

When I got burned out on open source projects like Xitami, I remember clearly how I felt. I simply stopped working on it, refused to answer any more emails, and told people to forget about it. You can tell when someone's burned out. They go offline, and everyone starts saying, "He's acting strange... depressed, or tired..."

Diagnosis is simple. Has someone worked a lot on a project that was not paying back in any way? Did she make exceptional sacrifices? Did he lose or abandon his job or studies to do the project? If you're answering "yes", it's burnout.

There are three simple techniques I've developed over the years to reduce the risk of burnout in the teams I work with:

* //No one is irreplaceable.// Working solo on a critical or popular project--the concentration of responsibility on one person who cannot set their own limits--is probably the main factor. It's a management truism: if someone in your organization is irreplaceable, get rid of him or her.

* //We need day jobs to pay the bills.// This can be hard, but seems necessary. Getting money from somewhere else makes it much easier to sustain a sacrificial project.

* //Teach people about burnout.// This should be a basic course in colleges and universities, as pro bono work becomes a more common way for young people to experiment professionally.

When someone is working alone on a critical project, you //know// they are going blow their fuses sooner or later. It's actually fairly predictable: something like 18-36 months depending on the individual and how much economic stress they face in their private lives. I've not seen anyone burn-out after half a year, nor last five years in a unrewarding project.

There is a simple cure for burnout that works in at least some cases: get paid decently for your work. However, this pretty much destroys the freedom of movement (across that infinite problem landscape) that the volunteer enjoys.

++ Patterns for Success

I'll end this code-free chapter with a series of patterns for success in software engineering. They aim to capture the essence of what divides glorious success from tragic failure. They were described as "religious maniacal dogma" by a manager, and "anything else would be effing insane" by a colleague, in a single day. For me, they are science. But treat the Lazy Perfectionist and others as tools to use, sharpen, and throw away if something better comes along.

+++ The Lazy Perfectionist

//Never design anything that's not a precise minimal answer to a problem we can identify and have to solve.//

The Lazy Perfectionist spends his idle time observing others and identifying problems that are worth solving. He looks for agreement on those problems, always asking, "What is the //real// problem". Then he moves, precisely and minimally, to build, or get others to build, a usable answer to one problem. He uses, or gets others to use those solutions. And he repeats this until there are no problems left to solve, or time or money runs out.

+++ The Benevolent Tyrant

//The control of a large force is the same principle as the control of a few men: it is merely a question of dividing up their numbers.// -- Sun Tzu

The Benevolent Tyrant divides large problems into smaller ones and throws them at groups to focus on. He brokers contracts between these groups, in the form of APIs and the "unprotocols" we'll read about in the next chapter. The Benevolent Tyrant constructs a supply chain that starts with problems, and results in usable solutions. He is ruthless about how the supply chain works, but does not tell people what to work on, nor how to do their work.

+++ The Earth and Sky

//The ideal team consists of two sides: one writing code, and one providing feedback.//

The Earth and Sky work together as a whole, in close proximity, but they communicate formally through issue tracking. Sky seeks out problems from others and from their own use of the product and feeds these to Earth. Earth rapidly answers with testable solutions. Earth and Sky can work through dozens of issues in a day. Sky talks to other users, and Earth talks to other developers. Earth and Sky may be two people, or two small groups.

+++ The Open Door

//The accuracy of knowledge comes from diversity.//

The Open Door accepts contributions from almost anyone. He does not argue quality or direction, instead allowing others to argue that and get more engaged. He calculates that even a troll will bring more diverse opinion to the group. He lets the group form its opinion about what goes into stable code, and he enforces this opinion with help of a Benevolent Tyrant.

+++ The Laughing Clown

//Perfection precludes participation.//

The Laughing Clown, often acting as the Happy Failure, makes no claim to high competence. Instead his antics and bumbling attempts provoke others into rescuing him from his own tragedy. Somehow however, he always identifies the right problems to solve. People are so busy proving him wrong they don't realize they're doing valuable work.

+++ The Mindful General

//Make no plans. Set goals, develop strategies and tactics.//

The Mindful General operates in unknown territory, solving problems that are hidden until they are nearby. Thus he makes no plans, but seeks opportunities, then exploits them rapidly and accurately. He develops tactics and strategies in the field, and teaches these to his men so they can move independently, and together.

+++ The Social Engineer

//If you know the enemy and know yourself, you need not fear the result of a hundred battles.// -- Sun Tzu

The Social Engineer reads the hearts and minds of those he works with and for. He asks, of everyone, "What makes this person angry, insecure, argumentative, calm, happy?" He studies their moods and dispositions. With this knowledge he can encourage those who are useful, and discourage those who are not. The Social Engineer never acts on his own emotions.

+++ The Constant Gardener

//He will win whose army is animated by the same spirit throughout all its ranks.// -- Sun Tzu

The Constant Gardener grows a process from a small seed, step-by-step as more people come into the project. He makes every change for a precise reason, with agreement from everyone. He never imposes a process from above but lets others come to consensus, and then he enforces that consensus. In this way, everyone owns the process together and by owning it, they are attached to it.

+++ The Rolling Stone

//After crossing a river, you should get far away from it.// -- Sun Tzu

The Rolling Stone accepts his own mortality and transience. He has no attachment to his past work. He accepts that all that we make is destined for the trash can, it is just a matter of time. With precise, minimal investments, he can move rapidly away from the past and stay focused on the present and near future. Above all, he has no ego and no pride to be hurt by the actions of others.

+++ The Pirate Gang

//Code, like all knowledge, works best as collective--not private--property.//

The Pirate Gang organizes freely around problems. It accepts authority insofar as authority provides goals and resources. The Pirate Gang owns and shares all it makes: every work is fully remixable by others in the Pirate Gang. The gang moves rapidly as new problems emerge, and is quick to abandon old solutions if those stop being relevant. No persons or groups can monopolize any part of the supply chain.

+++ The Flash Mob

//Water shapes its course according to the nature of the ground over which it flows.// -- Sun Tzu

The Flash Mob comes together in space and time as needed, then disperses as soon as they can. Physical closeness is essential for high-bandwidth communications. But over time it creates technical ghettos, where Earth gets separated from Sky. The Flash Mob tends to collect a lot of frequent flier miles.

+++ The Canary Watcher

//Pain is not, generally, a Good Sign.//

The Canary Watcher measures the quality of an organization by the their own pain level, and the observed pain levels of those with whom he works. He brings new participants into existing organizations so they can express the raw pain of the innocent. He may use alcohol to get others to verbalize their pain points. He asks others, and himself, "Are you happy in this process, and if not, why not?" When an organization causes pain in himself or others, he treats that as a problem to be fixed. People should feel joy in their work.

+++ The Hangman

//Never interrupt others when they are making mistakes.//

The Hangman knows that we learn only by making mistakes, and he gives others copious rope with which to learn. He only pulls the rope gently, when it's time. A little tug to remind the other of their precarious position. Allowing others to learn by failure gives the good reason to stay, and the bad excuse to leave. The Hangman is endlessly patient, because there is no shortcut to the learning process.

+++ The Historian

//Keeping the public record may be tedious, but it's the only way to prevent collusion.//

The Historian forces discussion into the public view, to prevent collusion to own areas of work. The Pirate Gang depends on full and equal communications that do not depend on momentary presence. No one really reads the archives, but the simply possibility stops most abuses. The Historian encourages the right tool for the job: email for transient discussions, IRC for chatter, wikis for knowledge, issue tracking for recording opportunities.

+++ The Provocateur

//When a man knows he is to be hanged in a fortnight, it concentrates his mind wonderfully.// -- Samuel Johnson

The Provocateur creates deadlines, enemies, and the occasional impossibility. Teams work best when they don't have time for the crap. Deadlines bring people together and focus the collective mind. An external enemy can move a passive team into action. The Provocateur never takes the deadline too seriously. The product is //always// ready to ship. But he gently reminds the team of the stakes: fail, and we all look for other jobs.

+++ The Mystic

//When people argue or complain, just write them a Sun Tzu quotation// -- Mikko Koppanen

The Mystic never argues directly. He knows that to argue with an emotional person only creates more emotion. Instead he side-steps the discussion. It's hard to be angry at a Chinese general, especially when he has been dead for 2,400 years. The Mystic plays Hangman when people insist on the right to get it wrong.
